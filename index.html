<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Qianyu Zhou, Shanghai Jiao Tong University"> 
<meta name="description" content="Qianyu Zhou's home page">
<meta name="google-site-verification" content="google1367f398cef8d4d4.html" />
<meta name="google-site-verification" content="google1367f398cef8d4d4.html" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title> Qianyu Zhou's homepage, SJTU</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Qianyu Zhou </font></h1>  <h1><font face="楷体"> 周千寓 </font></h1>
				</div>

				<h3><font face="Arial"> Ph.D Candidate </font></h3>
				<p><font face="Arial"> 
					<a href="https://dmcv.sjtu.edu.cn/" target="_blank"> Digital Media & Computer Vision (DMCV) Laboratory </a>  <br>
					<a href="https://www.cs.sjtu.edu.cn/en/" target="_blank"> Department of Computer Science and Engineering</a> <br>
					<a href="https://en.sjtu.edu.cn/" target="_blank"> Shanghai Jiao Tong University</a> <br>
					Shanghai, China <br>
					<br>
					Email: <a href="mailto:zhouqianyu@sjtu.edu.cn">zhouqianyu@sjtu.edu.cn</a> <br>
					<!--<a href="https://chaoqichen.github.io/CV_chaoqichen.pdf">[Curriculum Vitae]</a>-->
				</font></p>
			</td>
			<td>
				<img src="zqy.png" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2><font face="Arial"> Biography </font></h2>
<p style="text-align:justify";><font face="Arial">
	I am currently a Ph.D candidate at the Shanghai Jiao Tong Univeristy (SJTU), supervised by 
	Prof. <a href="https://dmcv.sjtu.edu.cn/people/" target="_blank">
Lizhuang Ma</a>. I am also selected into <a href="https://xsb.seiee.sjtu.edu.cn/xsb/info/35105.htm" target="_blank">
Wenjun Wu AI Honored Ph.D Class (Top 1%)</a> and <a href="https://yzb.sjtu.edu.cn/info/1004/2672.htm" target="_blank">
Zhiyuan Honored Ph.D Program (Top 2%)</a> of SJTU, co-advised by Dr. <a href="https://shijianping.me/" target="_blank">
Jianping Shi</a>.
Before that, I received the B.Sc degree from the College of Computer Science and Technology, Jilin University in 2019. Currently, I am interested in computer vision and transfer learning, especially domain adaptation and domain generalization for image classification, object detection and semantic segmentation.
</font></p> 

<!-- <p style="text-align:justify"><font face="Arial">
My research interest lies at the intersection of computer vision and machine learning.
Currently, I am working on (i) open-world perception and adaptation, (ii) out-of-domain generalization, and (iii) graph reasoning for vision tasks.
</font></p> -->
	
<!--<font color="red">Currently, I am working on domain generalization for semantic segmentation and object detection. I am looking for undergraduate or master students to engage in ongoing research papers. Don't hesitate to email me if you are interested.</font> <br><br>-->
	
<h2><font face="Arial"> News </h2>
<ul>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2023] One paper is selected into Top 3% Paper Recognition of all papers accepted at ICASSP 2023.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2023] One paper is accepted to the 1st Workshop on Vision-based InduStrial InspectiON (VISION) of CVPR 2023.  </p></li>  
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [04/2023] I am invited to serve as a reviewer for ACM MM 2023. </p></li>  
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2023] One paper is accepted to CVPR 2023 (25.78% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [02/2023] I am invited to serve as a reviewer for ICCV 2023. </p></li>    
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [01/2023] One paper is accepted to IEEE TPAMI (9% acceptance rate, IF=23.6). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [11/2022] One paper is accepted to IEEE TPAMI (9% acceptance rate, IF=23.6). </p></li>	
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [11/2022] I am invited to serve as a reviewer for CVPR 2023. </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [09/2022] One paper is accepted to IEEE TCSVT (15% acceptance rate, IF=8.4). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [08/2022] I am invited to serve as a Programme Committee member of AAAI 2023. </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [07/2022] One paper is accepted to ECCV 2022 (26% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2022] One paper is accepted to ACM MM 2022 (27.9% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2022] One paper is accepted to Pattern Recognition (19% acceptance rate, IF=8.0). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2022] One paper is accepted to CVIU (17% acceptance rate, IF=4.5). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2022] One paper is selected as an oral presentation of ICME 2022 (top 14.5%). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2022] I am invited to serve as a reviewer for ECCV 2022. </p></li>
</ul>

<!-- <h2><font face="Arial"> Preprints </font></h2>
<ul>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Self-Adversarial Disentangling for Specific Domain Adaptation <br> 
         <i>   <b>Qianyu Zhou</b>, Qiqi Gu, Jiangmiao Pang,  Xuequan Lu, Lizhuang Ma. </i><br> 
         Preprint, 2021. <br>
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">arxiv</a>] </font>

</ul> -->

<h2><font face="Arial"> Selected Publications </font></h2>
<p><font face="Arial"><a href="https://scholar.google.com/citations?hl=en&pli=1&user=KHg04fkAAAAJ">[Google Scholar]</a> (* indicates joint first author) </font></p> 
	
<ul>
<!--     <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Mix and Reason: Reasoning over Semantic Topology with Data Mixing for Domain Generalization <br> 
         <i>   <b>Chaoqi Chen</b>, Luyao Tang, Feng Liu, Gangming Zhao, Yue Huang, Yizhou Yu. </i><br> 
	       Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <br>
	 </p> </li>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Relation Matters: Foreground-aware Graph-based Relational Reasoning for Domain Adaptive Object Detection <br> 
         <i>   <b>Chaoqi Chen</b>, Jiongcheng Li, Hong-Yu Zhou, Xiaoguang Han, Yue Huang, Xinghao Ding, Yizhou Yu. </i><br> 
	       IEEE Transactions on Pattern Analysis and Machine Intelligence  (<b>TPAMI</b>), 2022. <br>
	 </p> </li>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Compound Domain Generalization via Meta-Knowledge Encoding <br> 
         <i>   <b>Chaoqi Chen</b>, Jiongcheng Li, Xiaoguang Han, Xiaoqing Liu, Yizhou Yu. </i><br> 
	       IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022. <br>
	 </p> </li>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Dual Bipartite Graph Learning: A General Approach for Domain Adaptive Object Detection <br> 
         <i>   <b>Chaoqi Chen</b>, Jiongcheng Li, Zebiao Zheng, Xinghao Ding, Yue Huang, Yizhou Yu. </i><br> 
	       IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021. <br> -->
	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            TransVOD: End-to-End Video Object Detection with Spatial-Temporal Transformers <br> 
         <i>   <b>Qianyu Zhou*</b>, Xiangtai Li*, Lu He*, Yibo Yang, Guangliang Cheng, Yunhai Tong, Lizhuang Ma, Dacheng Tao. </i><br> 
         IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9960850">paper</a>]
   [<a href="https://arxiv.org/pdf/2201.05047.pdf">arxiv</a>] 
   [<a href="https://ieeexplore.ieee.org/document/9960850">DOI</a>]
   [<a href="https://github.com/qianyuzqy/TransVOD_Lite">code1</a>]
   [<a href="https://github.com/qianyuzqy/TransVOD_plusplus">code2</a>]
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Self-Adversarial Disentangling for Specific Domain Adaptation <br> 
         <i>   <b>Qianyu Zhou</b>, Qiqi Gu, Jiangmiao Pang,  Xuequan Lu, Lizhuang Ma. </i><br> 
         IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10024368">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">arxiv</a>] 
   [<a href="https://ieeexplore.ieee.org/document/10024368">DOI</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Instance-Aware Domain Generalization for Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Ran Yi,  Shouhong Ding, Lizhuang Ma. </i><br> 
           IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023. <br>
     [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Instance-Aware_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2023_paper.pdf">paper</a>]
     [<a href="https://arxiv.org/pdf/2304.05640.pdf">arxiv</a>] 
     [<a href="https://github.com/qianyuzqy/IADG">code</a>]
      </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Context-Aware Mixup for Domain Adaptive Semantic Segmentation <br> 
         <i>   <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
	       IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), 2022. <br>
	 [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9889681">paper</a>]
	 [<a href="https://arxiv.org/pdf/2108.03557.pdf">arxiv</a>] 
     [<a href="https://ieeexplore.ieee.org/document/9889681">DOI</a>]
     [<a href="https://github.com/qianyuzqy/CAMix">code</a>]
     </font>
	 </p> </li>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Adaptive Mixture of Experts Learning for Generalizable Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou*</b>, Ke-Yue Zhang*, Taiping Yao*, Ran Yi,  Shouhong Ding, Lizhuang Ma. </i><br> 
	       The 30th ACM International Conference on Multimedia (<b>ACM MM</b>), 2022. <br>
	 [<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547769">paper</a>]
	 [<a href="https://arxiv.org/pdf/2207.09868.pdf">arxiv</a>]
     [<a href="https://dl.acm.org/doi/10.1145/3503161.3547769">DOI</a>]
      </font>
	 </p> </li>
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Generative Domain Adaptation for Face Anti-Spoofing  <br> 
	 <i>   <b>Qianyu Zhou*</b>, Ke-Yue Zhang*, Taiping Yao, Ran Yi, Kekai Sheng, Shouhong Ding, Lizhuang Ma. </i><br> 
	       European Conference on Computer Vision (<b>ECCV</b>), 2022. <br>
	 [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650328.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2207.10015.pdf">arxiv</a>] 
   [<a href="https://link.springer.com/chapter/10.1007/978-3-031-20065-6_20">DOI</a>]
   </font>
	 </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Uncertainty-Aware Consistency Regularization for Cross-Domain Semantic Segmentation <br> 
         <i>   <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Guangliang  Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
	       Computer Vision and Image Understanding (<b>CVIU</b>), 2022. <br>
   [<a href="https://www.sciencedirect.com/science/article/pii/S1077314222000625">paper</a>]
   [<a href="https://arxiv.org/pdf/2004.08878.pdf">arxiv</a>]
   [<a href="https://www.sciencedirect.com/science/article/pii/S1077314222000625">DOI</a>] 
   </font>
   </p> </li>
  
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization <br> 
         <i>   <b>Qianyu Zhou</b>, Chuyun Zhuang,  Ran Yi, Xuequan Lu, Lizhuang Ma. </i><br> 
         IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2022, oral presentation. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9859793">paper</a>]
   [<a href="https://arxiv.org/pdf/2110.05170">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/9859793">DOI</a>]
   [<a href="https://github.com/qianyuzqy/RCCR">code</a>] 
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            PIT: Position-Invariant Transform for Cross-FoV Domain Adaptation <br> 
         <i>   Qiqi Gu*, <b>Qianyu Zhou*</b>, Minghao Xu, Zhengyang Feng, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
         IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2021. <br>
   [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_PIT_Position-Invariant_Transform_for_Cross-FoV_Domain_Adaptation_ICCV_2021_paper.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.07142.pdf">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/9711500">DOI</a>] 
   [<a href="https://github.com/sheepooo/PIT-Position-Invariant-Transform">code</a>]</font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            End-to-End Video Object Detection with Spatial-Temporal Transformers <br> 
         <i>   Lu He*, <b>Qianyu Zhou*</b>, Xiangtai Li*, Li Niu, Guangliang Cheng, Xiao Li, Wenxuan Liu, Yunhai Tong, Lizhuang Ma, Liqing Zhang. </i><br> 
         The 29th ACM International Conference on Multimedia (<b>ACM MM</b>), 2021. <br>
   [<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475285">paper</a>]
   [<a href="https://arxiv.org/pdf/2105.10920.pdf">arxiv</a>]
   [<a href="https://dl.acm.org/doi/10.1145/3474085.3475285">DOI</a>]
   [<a href="https://github.com/SJTU-LuHe/TransVOD">code</a>] </font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            DMT: Dynamic Mutual Training for Semi-Supervised Learning <br> 
         <i>   Zhengyang Feng*, <b>Qianyu Zhou*</b>, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
         Patter Recognition (<b>PR</b>), 2022. <br>
   [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">paper</a>]
   [<a href="https://arxiv.org/pdf/2004.08514.pdf">arxiv</a>]
   [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">DOI</a>]
   [<a href="https://github.com/voldemortX/DST-CBC">code</a>] </font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rethinking Implicit Neural Representations for Vision Learners <br> 
         <i>   Yiran Song, <b>Qianyu Zhou</b>, Lizhuang Ma. </i><br> 
         IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023. <br>
         Top 3% Paper Recognition of all papers accepted at ICASSP 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10094875">paper</a>]
   [<a href="https://arxiv.org/pdf/2211.12040.pdf">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/10094875">DOI</a>]

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Label-free Regional Consistency for Image-to-Image Translation <br> 
         <i>   Shaohua Guo, <b>Qianyu Zhou</b>, Zhou Ye, Qiqi Gu, Junshu Tang, Zhengyang Feng, Lizhuang Ma. </i><br> 
         IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2021. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9428211">paper</a>]
   [<a href="https://ieeexplore.ieee.org/document/9428211">DOI</a>]

</ul>
	


<h2><font face="Arial"> Experience </h2>
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Research Intern, <a href="https://www.catl.com/en/">Contemporary Amperex Technology Co., Ltd </a>  (Mentor: <a href="https://hujiecpp.github.io/">Jie Hu</a> and <a href="https://scholar.google.com.au/citations?user=yw-rcj4AAAAJ&hl=en">Guannan Jiang</a>) <div style="float:right; text-align:right">May. 2023 - Aug. 2023</div><br>
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<!-- <li>Remote Intern, <a href="http://rongcheer.com/enproducts.asp">Rongcheer Industrial Technology Co., Ltd </a> (Manager: Yan Tang and <a href="http://rongcheer.com/NewsShow.asp?Bid=32">Wenbing Zhu</a>) <div style="float:right; text-align:right">April. 2023-May. 2023</div><br> -->
<li>Research Intern, <a href="https://open.youtu.qq.com/#/open">Youtu Lab</a>, <a href="https://www.tencent.com/en-us/index.html">Tencent</a> (Mentor: <a href="https://sndler.github.io/">Taiping Yao</a> and <a href="https://scholar.google.com.hk/citations?user=i2ah3-wAAAAJ&hl=en">Ke-Yue Zhang</a>) <div style="float:right; text-align:right">July. 2021 - Nov. 2022</div><br>
<li>Research Intern, <a href="https://www.sensetime.com/en">Sensetime Reserch</a> (Mentor: <a href="https://scholar.google.com.hk/citations?user=FToOC-wAAAAJ&hl=en">Guangliang Cheng</a> and <a href="https://scholar.google.com.hk/citations?user=mwsxrm4AAAAJ&hl=en">Jianping Shi</a>)<div style="float:right; text-align:right">July. 2019 - Mar. 2021</div><br>
</p>
</ul>




<h2><font face="Arial"> Academic Services </font></h2>
<ul style="list-style-type:none"> 
	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Journal Reviewer </strong> <br> </font> </p> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        International Journal of Computer Vision (IJCV) </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Image Processing (TIP) </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Multimedia (TMM) </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Information Fusion </p>
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Neurocomputing </p> -->
    </li>
	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Conference Reviewer </strong> <br> </font> </p> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022-2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Computer Vision (ICCV), 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        European Conference on Computer Vision (ECCV), 2022 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        AAAI Conference on Artificial Intelligence (AAAI), 2023-2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        ACM International Conference on Multimedia (ACM MM), 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Multimedia and Expo (ICME), 2023 </p></li>
</ul>
		
<!-- <h2><font face="Arial"> Honors &amp; Awards </h2>
  
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>National Scholarship, Ministry of Education of P.R. China<div style="float:right; text-align:right">2016-2018</div><br>
<li>President Scholarship of Jilin University<div style="float:right; text-align:right">2019</div><br>
<li>Outstanding Graduates of Jilin University<div style="float:right; text-align:right">2019</div><br>
</p>
</ul> -->


<!-- hitwebcounter Code START
 -->

<!-- <a href="https://www.hitwebcounter.com" target="_blank">
Visitor number:
<img src="https://hitwebcounter.com/counter/counter.php?page=8093152&style=0001&nbdigits=8&type=page&initCount=0" title="Free Counter" Alt="web counter"   border="0" /></a> -->

<div id="footer">
	<div id="footer-text"></div>
</div>
	<p></p><center>
        <br>
            © Qianyu Zhou | Last updated: 06/2023
        </center><p></p>

</b></b></b></div><b><b><b>

</b></b></b></body>
<!-- {% include analytics.html %}
 -->
</html>

