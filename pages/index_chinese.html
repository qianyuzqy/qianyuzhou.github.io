<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Qianyu Zhou, Shanghai Jiao Tong University"> 
<meta name="description" content="Qianyu Zhou's home page">
<meta name="google-site-verification" content="google1367f398cef8d4d4.html" />
<meta name="google-site-verification" content="google1367f398cef8d4d4.html" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title> Qianyu Zhou's homepage, SJTU</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');


</script>
</head>
<body>

<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#biography">简介</a>
        <a href="#news">动态</a>
        <a href="#publication">学术论文</a>
        <a href="#experience">实习经历</a>
        <a href="#service">学术服务</a>
        <a href="#honors">荣誉奖项</a>
    </div>
</nav>

<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="楷体"> 周千寓 </font></h1>
				</div>

				<h3><font face="楷体"> 博士研究生 </font></h3>
				<p><font face="楷体"> 
					<a href="https://www.sjtu.edu.cn/" target="_blank"> 上海交通大学 </a> <br>
                    <a href="https://www.cs.sjtu.edu.cn/" target="_blank"> 计算机科学与工程系</a> <br>
                    <a href="https://dmcv.sjtu.edu.cn/" target="_blank"> 数字媒体与计算机视觉实验室（DMCV Lab） </a>  <br>
					<br>
					电子邮箱 <a href="mailto:zhouqianyu@sjtu.edu.cn">zhouqianyu@sjtu.edu.cn</a> <br>
					<!--<a href="https://chaoqichen.github.io/CV_chaoqichen.pdf">[Curriculum Vitae]</a>-->
				</font></p>
			</td>
			<td>
				<img src="zqy.png" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>
 
<div id="biography">
<h2><font face="楷体"> 个人简介 </font></h2>
<!-- <a name="Biography" /> -->
<p style="text-align:justify";><font face="楷体">
周千寓，<a href="https://www.sjtu.edu.cn/" target="_blank"> 上海交通大学</a><a href="https://www.cs.sjtu.edu.cn/" target="_blank"> 计算机科学与工程系</a>博士生, 师从国家杰出青年科学基金获得者<a href="https://baike.baidu.com/link?url=IHD7QKT8ub7YZ4bnFLx9dDOA4QbDAvbes_Vp6ouI7wBQUewuizuU5P8rTw_cnqUhacWFWQMmBbA-x3u6gCyd-L9pf7P_wSO_xx_RVLnzxvLah9xXHkqRdFvldn4fmNLr" target="_blank">马利庄</a>教授。 入选<a href="https://xsb.seiee.sjtu.edu.cn/xsb/info/35105.htm" target="_blank">
上海交通大学首届吴文俊人工智能荣誉博士生班</a>、<a href="https://yzb.sjtu.edu.cn/info/1004/2672.htm" target="_blank">
上海交通大学“博士生致远荣誉计划”</a>，并由<a href="https://shijianping.me/" target="_blank">石建萍博士</a>联合指导。 在此之前，于2019年在<a href="http://global.jlu.edu.cn/" target="_blank">吉林大学</a><a href="http://ccst.jlu.edu.cn/" target="_blank">计算机科学与技术学院</a>获得理学学士学位. 目前我的研究兴趣主要为计算机视觉与迁移学习。

<!-- </font></p> 
<div class="navbar-collapse collapse">
<h2>
<a href="#Biography">Biography|</a>
<a href="#News">News|</a>
<a href="#Publications">Publications|</a>
<a href="#Services">Services|</a>  
<a href="#Experience">Experience</a>   
</h2>
</div>  -->

<!-- <p style="text-align:justify"><font face="Arial">
My research interest lies at the intersection of computer vision and machine learning.
Currently, I am working on (i) open-world perception and adaptation, (ii) out-of-domain generalization, and (iii) graph reasoning for vision tasks.
</font></p> -->
	
<!--<font color="red">Currently, I am working on domain generalization for semantic segmentation and object detection. I am looking for undergraduate or master students to engage in ongoing research papers. Don't hesitate to email me if you are interested.</font> <br><br>-->

<div id="news">
<h2><font face="Arial"> 最新动态 </h2>
<!-- <a name="News" /> -->
<ul>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [09/2023] I won the Yuanqing Yang Ph.D Fellowship (3 recipients per year in SJTU).  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [08/2023] One paper won the Best Poster Award in CAD/Graphics 2023.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2023] One paper is selected into Top 3% Paper Recognition of all papers accepted at ICASSP 2023.  </p></li> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2023] One paper is accepted to the 1st Workshop on Vision-based InduStrial InspectiON (VISION) of CVPR 2023.  </p></li>  
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [04/2023] I am invited to serve as a reviewer for ACM MM 2023. </p></li>   -->
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2023] One paper is accepted to CVPR 2023 (25.78% acceptance rate). </p></li>
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [02/2023] I am invited to serve as a reviewer for ICCV 2023. </p></li>   -->  
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [01/2023] One paper is accepted to IEEE TPAMI (9% acceptance rate, IF=23.6). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [11/2022] One paper is accepted to IEEE TPAMI (9% acceptance rate, IF=23.6). </p></li>	
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [11/2022] I am invited to serve as a reviewer for CVPR 2023. </p></li> -->
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [09/2022] One paper is accepted to IEEE TCSVT (15% acceptance rate, IF=8.4). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [08/2022] I am invited to serve as a Programme Committee member of AAAI 2023. </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [07/2022] One paper is accepted to ECCV 2022 (26% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [06/2022] One paper is accepted to ACM MM 2022 (27.9% acceptance rate). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2022] One paper is accepted to Pattern Recognition (19% acceptance rate, IF=8.0). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [05/2022] One paper is accepted to CVIU (17% acceptance rate, IF=4.5). </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2022] One paper is selected as an oral presentation of ICME 2022 (top 14.5%). </p></li>
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">    
        [03/2022] I am invited to serve as a reviewer for ECCV 2022. </p></li> -->
</ul>

<!-- <h2><font face="Arial"> Preprints </font></h2>
<ul>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Self-Adversarial Disentangling for Specific Domain Adaptation <br> 
         <i>   <b>Qianyu Zhou</b>, Qiqi Gu, Jiangmiao Pang,  Xuequan Lu, Lizhuang Ma. </i><br> 
         Preprint, 2021. <br>
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">arxiv</a>] </font>

</ul> -->

<div id="publication">
<h2><font face="楷体"> 学术论文 </font></h2>
<!-- <a name="Publications" /> -->
<p><font face="楷体"><a href="https://scholar.google.com/citations?hl=en&pli=1&user=KHg04fkAAAAJ">[谷歌学术]</a> (* 指共同第一作者) </font></p> 
	
<ul>
	<li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            TransVOD: End-to-End Video Object Detection with Spatial-Temporal Transformers <br> 
         <i>   <b>Qianyu Zhou*</b>, Xiangtai Li*, Lu He*, Yibo Yang, Guangliang Cheng, Yunhai Tong, Lizhuang Ma, Dacheng Tao. </i><br> 
         IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9960850">paper</a>]
   [<a href="https://arxiv.org/pdf/2201.05047.pdf">arxiv</a>] 
   [<a href="https://ieeexplore.ieee.org/document/9960850">DOI</a>]
   [<a href="https://github.com/SJTU-LuHe/TransVOD">code1</a>]
   [<a href="https://github.com/qianyuzqy/TransVOD_Lite">code2</a>]
   [<a href="https://github.com/qianyuzqy/TransVOD_plusplus">code3</a>]
   [<a href="bibs/TPAMI_2023_TransVOD.txt">bib</a>]
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Self-Adversarial Disentangling for Specific Domain Adaptation <br> 
         <i>   <b>Qianyu Zhou</b>, Qiqi Gu, Jiangmiao Pang,  Xuequan Lu, Lizhuang Ma. </i><br> 
         IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>IEEE TPAMI</b>), 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10024368">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.03553.pdf">arxiv</a>] 
   [<a href="https://ieeexplore.ieee.org/document/10024368">DOI</a>]
   [<a href="bibs/TPAMI_2023_SAD.txt">bib</a>]
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Instance-Aware Domain Generalization for Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou</b>, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Ran Yi,  Shouhong Ding, Lizhuang Ma. </i><br> 
           IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023. <br>
     [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Instance-Aware_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2023_paper.pdf">paper</a>]
     [<a href="https://arxiv.org/pdf/2304.05640.pdf">arxiv</a>] 
     [<a href="https://doi.org/10.1109/CVPR52729.2023.01959">DOI</a>]
     [<a href="https://github.com/qianyuzqy/IADG">code</a>]
     [<a href="bibs/CVPR_2023_IADG.txt">bib</a>]
      </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Context-Aware Mixup for Domain Adaptive Semantic Segmentation <br> 
         <i>   <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
	       IEEE Transactions on Circuits and Systems for Video Technology (<b>IEEE TCSVT</b>), 2023. <br>
	 [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9889681">paper</a>]
	 [<a href="https://arxiv.org/pdf/2108.03557.pdf">arxiv</a>] 
     [<a href="https://ieeexplore.ieee.org/document/9889681">DOI</a>]
     [<a href="https://github.com/qianyuzqy/CAMix">code</a>]
     [<a href="bibs/TCSVT_2023_CAMix.txt">bib</a>]
     </font>
	 </p> </li>
	
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Adaptive Mixture of Experts Learning for Generalizable Face Anti-Spoofing <br> 
         <i>   <b>Qianyu Zhou*</b>, Ke-Yue Zhang*, Taiping Yao*, Ran Yi,  Shouhong Ding, Lizhuang Ma. </i><br> 
	       The 30th ACM International Conference on Multimedia (<b>ACM MM</b>), 2022. <br>
	 [<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547769">paper</a>]
	 [<a href="https://arxiv.org/pdf/2207.09868.pdf">arxiv</a>]
     [<a href="https://dl.acm.org/doi/10.1145/3503161.3547769">DOI</a>]
     [<a href="bibs/MM_2022_AMEL.txt">bib</a>]
      </font>
	 </p> </li>
   
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Generative Domain Adaptation for Face Anti-Spoofing  <br> 
	 <i>   <b>Qianyu Zhou*</b>, Ke-Yue Zhang*, Taiping Yao, Ran Yi, Kekai Sheng, Shouhong Ding, Lizhuang Ma. </i><br> 
	       European Conference on Computer Vision (<b>ECCV</b>), 2022. <br>
	 [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650328.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2207.10015.pdf">arxiv</a>] 
   [<a href="https://link.springer.com/chapter/10.1007/978-3-031-20065-6_20">DOI</a>]
   [<a href="bibs/ECCV_2022_GDA.txt">bib</a>]
   </font>
	 </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Uncertainty-Aware Consistency Regularization for Cross-Domain Semantic Segmentation <br> 
         <i>   <b>Qianyu Zhou</b>, Zhengyang Feng, Qiqi Gu, Guangliang  Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
	       Computer Vision and Image Understanding (<b>CVIU</b>), 2022. <br>
   [<a href="https://www.sciencedirect.com/science/article/pii/S1077314222000625">paper</a>]
   [<a href="https://arxiv.org/pdf/2004.08878.pdf">arxiv</a>]
   [<a href="https://www.sciencedirect.com/science/article/pii/S1077314222000625">DOI</a>]
   [<a href="bibs/CVIU_2022_UACR.txt">bib</a>] 
   </font>
   </p> </li>
  
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization <br> 
         <i>   <b>Qianyu Zhou</b>, Chuyun Zhuang,  Ran Yi, Xuequan Lu, Lizhuang Ma. </i><br> 
         IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2022, oral presentation. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9859793">paper</a>]
   [<a href="https://arxiv.org/pdf/2110.05170">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/9859793">DOI</a>]
   [<a href="https://github.com/qianyuzqy/RCCR">code</a>]
   [<a href="bibs/ICME_2022_RCCR.txt">bib</a>] 
   </font>
   </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            PIT: Position-Invariant Transform for Cross-FoV Domain Adaptation <br> 
         <i>   Qiqi Gu*, <b>Qianyu Zhou*</b>, Minghao Xu, Zhengyang Feng, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
         IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2021. <br>
   [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_PIT_Position-Invariant_Transform_for_Cross-FoV_Domain_Adaptation_ICCV_2021_paper.pdf">paper</a>]
   [<a href="https://arxiv.org/pdf/2108.07142.pdf">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/9711500">DOI</a>] 
   [<a href="https://github.com/sheepooo/PIT-Position-Invariant-Transform">code</a>]
   [<a href="bibs/ICCV_2021_PIT.txt">bib</a>]
   </font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            End-to-End Video Object Detection with Spatial-Temporal Transformers <br> 
         <i>   Lu He*, <b>Qianyu Zhou*</b>, Xiangtai Li*, Li Niu, Guangliang Cheng, Xiao Li, Wenxuan Liu, Yunhai Tong, Lizhuang Ma, Liqing Zhang. </i><br> 
         The 29th ACM International Conference on Multimedia (<b>ACM MM</b>), 2021. <br>
   [<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475285">paper</a>]
   [<a href="https://arxiv.org/pdf/2105.10920.pdf">arxiv</a>]
   [<a href="https://dl.acm.org/doi/10.1145/3474085.3475285">DOI</a>]
   [<a href="https://github.com/SJTU-LuHe/TransVOD">code</a>] 
   [<a href="bibs/MM_2021_TransVOD.txt">bib</a>]
   </font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            DMT: Dynamic Mutual Training for Semi-Supervised Learning <br> 
         <i>   Zhengyang Feng*, <b>Qianyu Zhou*</b>, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma. </i><br> 
         Patter Recognition (<b>PR</b>), 2022. <br>
   [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">paper</a>]
   [<a href="https://arxiv.org/pdf/2004.08514.pdf">arxiv</a>]
   [<a href="https://www.sciencedirect.com/science/article/pii/S0031320322002588">DOI</a>]
   [<a href="https://github.com/voldemortX/DST-CBC">code</a>]
   [<a href="bibs/PR_2022_DMT.txt">bib</a>]
   </font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Rethinking Implicit Neural Representations for Vision Learners <br> 
         <i>   Yiran Song, <b>Qianyu Zhou</b>, Lizhuang Ma. </i><br> 
         IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023. <br>
         Top 3% Paper Recognition of all papers accepted at ICASSP 2023. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10094875">paper</a>]
   [<a href="https://arxiv.org/pdf/2211.12040.pdf">arxiv</a>]
   [<a href="https://ieeexplore.ieee.org/document/10094875">DOI</a>]
   [<a href="bibs/ICASSP_2023_IRNS.txt">bib</a>]
   </font>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Label-free Regional Consistency for Image-to-Image Translation <br> 
         <i>   Shaohua Guo, <b>Qianyu Zhou</b>, Zhou Ye, Qiqi Gu, Junshu Tang, Zhengyang Feng, Lizhuang Ma. </i><br> 
         IEEE International Conference on Multimedia and Expo (<b>ICME</b>), 2021. <br>
   [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9428211">paper</a>]
   [<a href="https://ieeexplore.ieee.org/document/9428211">DOI</a>]
   [<a href="bibs/ICME_2021_LFRC.txt">bib</a>]
   </font>
</ul>
	
<div id="experience">
<h2><font face="楷体"> 实习经历 </font></h2>
<!-- <a name="Experience" /> -->
<ul>
    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Research Intern at <a href="https://www.catl.com/en/">Contemporary Amperex Technology Co., Ltd (CATL)</a>, Ningde, P.R.China. (May. 2023 - Aug. 2023)<br> 
         Worked on surface defect detection, quality inspection for industrial manufacturing.<br> 
         Collaborators: <a href="https://hujiecpp.github.io/">Jie Hu</a> and <a href="https://scholar.google.com.au/citations?user=yw-rcj4AAAAJ&hl=en">Guannan Jiang</a> <br>
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Research Intern at <a href="https://open.youtu.qq.com/#/open">Youtu Lab</a>, <a href="https://www.tencent.com/en-us/index.html">Tencent</a>, Shanghai, P.R.China. (July. 2021 - Nov. 2022)<br> 
         Worked on face anti-spoofing, biometrics security.<br> 
         Mentor: <a href="https://sndler.github.io/">Taiping Yao</a> and <a href="https://scholar.google.com.hk/citations?user=i2ah3-wAAAAJ&hl=en">Ke-Yue Zhang</a> <br>
   </font>
     </p> </li>

    <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 10px; margin-bottom: 10px;"><font face="Arial" size="3"><meta charset="utf-8">
            Research Intern at <a href="https://www.sensetime.com/en">Sensetime Reserch</a>, Beijing & Shanghai, P.R.China. (July. 2019 - Mar. 2021)<br> 
         Worked on scene understanding, autonomous driving. <br> 
         Mentor: <a href="https://scholar.google.com.hk/citations?user=FToOC-wAAAAJ&hl=en">Guangliang Cheng</a> and <a href="https://scholar.google.com.hk/citations?user=mwsxrm4AAAAJ&hl=en">Jianping Shi</a> <br>
   </font>
     </p> </li>

</ul>


<!-- <h2><font face="Arial"> Experience </h2>
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Research Intern, <a href="https://www.catl.com/en/">Contemporary Amperex Technology Co., Ltd </a>  (Mentor: <a href="https://hujiecpp.github.io/">Jie Hu</a> and <a href="https://scholar.google.com.au/citations?user=yw-rcj4AAAAJ&hl=en">Guannan Jiang</a>) <div style="float:right; text-align:right">May. 2023 - Aug. 2023</div><br>
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Remote Intern, <a href="http://rongcheer.com/enproducts.asp">Rongcheer Industrial Technology Co., Ltd </a> (Manager: Yan Tang and <a href="http://rongcheer.com/NewsShow.asp?Bid=32">Wenbing Zhu</a>) <div style="float:right; text-align:right">April. 2023-May. 2023</div><br>
<li>Research Intern, <a href="https://open.youtu.qq.com/#/open">Youtu Lab</a>, <a href="https://www.tencent.com/en-us/index.html">Tencent</a> (Mentor: <a href="https://sndler.github.io/">Taiping Yao</a> and <a href="https://scholar.google.com.hk/citations?user=i2ah3-wAAAAJ&hl=en">Ke-Yue Zhang</a>) <div style="float:right; text-align:right">July. 2021 - Nov. 2022</div><br>
<li>Research Intern, <a href="https://www.sensetime.com/en">Sensetime Reserch</a> (Mentor: <a href="https://scholar.google.com.hk/citations?user=FToOC-wAAAAJ&hl=en">Guangliang Cheng</a> and <a href="https://scholar.google.com.hk/citations?user=mwsxrm4AAAAJ&hl=en">Jianping Shi</a>)<div style="float:right; text-align:right">July. 2019 - Mar. 2021</div><br>
</p>
</ul> -->

<div id="service">
<h2><font face="楷体"> 学术服务 </font></h2>
<!-- <a name="Services" /> -->
<ul style="list-style-type:none"> 
	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Journal Reviewer </strong> <br> </font> </p> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        International Journal of Computer Vision (IJCV) </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Image Processing (TIP) </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Multimedia (TMM) </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </p>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Information Fusion </p>
<!--     <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Neurocomputing </p> -->
    </li>
	 <li> <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Conference Reviewer </strong> <br> </font> </p> 
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022-2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Computer Vision (ICCV), 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        European Conference on Computer Vision (ECCV), 2022 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        AAAI Conference on Artificial Intelligence (AAAI), 2023-2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        ACM International Conference on Multimedia (ACM MM), 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Multimedia and Expo (ICME), 2023 </p></li>
</ul>

<div id="honors">
<h2><font face="楷体"> 荣誉奖项 </h2>
<!-- <a name="Honors" /> -->
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>Zhiyuan Honored Ph.D Fellowship, Shanghai Jiao Tong University <div style="float:right; text-align:right">2019-2024</div><br>
<li>Wenjun wu AI Honored Ph.D Fellowship, Shanghai Jiao Tong University <div style="float:right; text-align:right">2019-2024</div><br>
<li>Yuanqing Yang Ph.D Fellowship, Shanghai Jiao Tong University <div style="float:right; text-align:right">2023</div><br>
<li>Best Poster Award in CAD/Graphics 2023 <div style="float:right; text-align:right">2023</div><br>  
<li>Top 3% Paper Recognition of all papers accepted at ICASSP 2023 <div style="float:right; text-align:right">2023</div><br>
<li>First Class Scholarship of DMCV Lab, Shanghai Jiao Tong University <div style="float:right; text-align:right">2022</div><br>
<li>National Scholarship, Ministry of Education of P.R. China<div style="float:right; text-align:right">2016-2018</div><br>
<li>President Scholarship of Jilin University<div style="float:right; text-align:right">2019</div><br>
<li>Outstanding Graduates of Jilin University<div style="float:right; text-align:right">2019</div><br>
</p>
</ul>


<!-- hitwebcounter Code START
 -->

<!-- <a href="https://www.hitwebcounter.com" target="_blank">
Visitor number:
<img src="https://hitwebcounter.com/counter/counter.php?page=8093152&style=0001&nbdigits=8&type=page&initCount=0" title="Free Counter" Alt="web counter"   border="0" /></a> -->

<div id="footer">
	<div id="footer-text"></div>
</div>
	<p></p><center>
        <br>
            © Qianyu Zhou | Last updated: 09/2023
        </center><p></p>

</b></b></b></div><b><b><b>

</b></b></b></body>
<!-- {% include analytics.html %}
 -->
</html>

